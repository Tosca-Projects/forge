tosca_definitions_version: alien_dsl_1_4_0

metadata:
  template_name: org.ystia.logstash.linux.bash
  template_version: 1.0-SNAPSHOT
  template_author: Bull

description:

imports:
  - tosca-normative-types:1.0.0-ALIEN14
  - org.ystia.common:1.0-SNAPSHOT
  - org.ystia.consul.pub:1.0-SNAPSHOT
  - org.ystia.java.pub:1.0-SNAPSHOT
  - org.ystia.kafka.pub:1.0-SNAPSHOT
  # TODO (HJo) : import kafka.linux.bash instead of kafka.pub (Janus issue)
  - org.ystia.kafka.linux.bash:1.0-SNAPSHOT
  - org.ystia.elasticsearch.pub:1.0-SNAPSHOT
  - org.ystia.logstash.pub:1.0-SNAPSHOT

node_types:
  org.ystia.logstash.linux.bash.nodes.Logstash:
    derived_from: org.ystia.consul.pub.nodes.ConsulUser
    description: Logstash component from Elastic Stack for linux
    tags:
      icon: /images/logstash-icon.png
    attributes:
      java_home: { get_operation_output: [ SELF, Configure, pre_configure_source, JAVA_HOME ] }
      ls_home: { get_operation_output: [ SELF, Standard, create, LOGSTASH_HOME ] }
    properties:
      component_version:
        type: version
        description: Version of the installed Logstash component
        default: 5.1.1
        constraints:
          - valid_values: [5.1.1, 5.1.2, 5.2.2, 5.3.3, 5.4.3, 5.5.3, 5.6.2]
      repository:
         type: string
         description: >
           This property give the opportunity to specify an alternative download repository for this component artifact.
           It is your responsibility to provide an accessible download url and to store required artifacts on it.
           You should specify only the base repository url. Artifacts names will be appended to it, so this property could be shared among
           several components using the inputs feature.
         required: false
         default: https://artifacts.elastic.co/downloads/logstash
         constraints:
           - pattern: ^(http|https|ftp)://.+/.*$
      auto_reload:
        type: boolean
        description: Monitor configuration changes and reload whenever it is changed
        default: false
      reload_interval:
        type: integer
        description: How frequently to poll the configuration location for changes, in seconds
        default: 60
      stdout:
        type: boolean
        description: Define the stdout logstash output, to allow to see the events pipeline.
        default: false
      heap_size:
        type: string
        default: "1G"
        description: >
          This property allows to set the heap memory size that is allocated to Logstash java process,
          It allocates the same value to both initial and maximum values (ie -Xms and -Xmx java options).
        constraints:
          - pattern: "[1-9][0-9]*[kKmMgG]"
      log_level:
        type: string
        description: >
          Define Logstash log level. By default very few logs are generated by Logstash.
          All logs are redirected to a file except if you set 'stdout' to 'true'.
        default: "warn"
        constraints:
          - valid_values: [ "fatal", "error", "warn", "info", "debug", "trace" ]
    capabilities:
      logstash_resource:
        type: org.ystia.logstash.pub.capabilities.LogstashEndpoint
      connector_host:
        type: org.ystia.logstash.pub.capabilities.LogstashConnectorHosting
        occurrences: [0,unbounded]
    requirements:
      - host:
          capability: org.ystia.java.pub.capabilities.JavaHosting
          relationship: org.ystia.java.pub.relationships.HostedOnJavaRuntime
          occurrences: [1, 1]
      - search_endpoint:
          capability: org.ystia.elasticsearch.pub.capabilities.SearchEndpoint
          relationship: org.ystia.logstash.linux.bash.relationships.LogstashToElasticsearch
          occurrences: [0,1]
      - kafka_output:
          capability: org.ystia.kafka.pub.capabilities.KafkaTopic
          relationship: org.ystia.logstash.linux.bash.relationships.LogstashToKafka
          occurrences: [0,1]
      - kafka_input:
          capability: org.ystia.kafka.pub.capabilities.KafkaTopic
          relationship: org.ystia.logstash.linux.bash.relationships.KafkaToLogstash
          occurrences: [0,1]
    interfaces:
      Standard:
          create:
            inputs:
              REPOSITORY: { get_property: [SELF, repository] }
              LS_VERSION: { get_property: [SELF, component_version] }
            implementation: scripts/logstash_install.sh
          configure:
            inputs:
              STDOUT: { get_property: [SELF, stdout] }
              LOGSTASH_HEAP_SIZE: { get_property: [SELF, heap_size] }
              JAVA_HOME: { get_attribute: [SELF, java_home] }
              LOGSTASH_HOME: { get_attribute: [SELF, ls_home] }
              AUTO_RELOAD: { get_property: [SELF, auto_reload] }
              RELOAD_INTERVAL: { get_property: [SELF, reload_interval] }
              LOGSTASH_LOG_LEVEL: { get_property: [SELF, log_level] }
            implementation: scripts/logstash_configure.sh
          start:
            inputs:
              LOGSTASH_HOME: { get_attribute: [SELF, ls_home] }
            implementation: scripts/logstash_start.sh
          stop:
            inputs:
              LOGSTASH_HOME: { get_attribute: [SELF, ls_home] }
            implementation: scripts/logstash_stop.sh
      custom:
          change_input:
            inputs:
              url:
                type: string
                description: Input param for change_input
                required: true
              AUTO_RELOAD: { get_property: [SELF, auto_reload] }
              LOGSTASH_HOME: { get_attribute: [SELF, ls_home] }
            implementation: scripts/logstash_changeInput.sh
          change_output:
            inputs:
              url:
                type: string
                description: Input param for change_output
                required: true
              AUTO_RELOAD: { get_property: [SELF, auto_reload] }
              LOGSTASH_HOME: { get_attribute: [SELF, ls_home] }
            implementation: scripts/logstash_changeOutput.sh
          change_filter:
            inputs:
              url:
                type: string
                description: Input param for change_filter
                required: true
              AUTO_RELOAD: { get_property: [SELF, auto_reload] }
              LOGSTASH_HOME: { get_attribute: [SELF, ls_home] }
            implementation: scripts/logstash_changeFilter.sh
    artifacts:
      - scripts:
          file: scripts
          type: tosca.artifacts.File
      - conf:
          file: conf
          type: tosca.artifacts.File
      - certificates:
          file: certificates
          type: tosca.artifacts.File
      - private_key:
          file: certificates/default-logstash-forwarder.key
          type: tosca.artifacts.File
      - certificate:
          file: certificates/default-logstash-forwarder.crt
          type: tosca.artifacts.File
      - inputs_conf:
          file: conf/1-1_logstash_inputs.conf
          type: tosca.artifacts.File
      - filters_conf:
          file: conf/2-1_logstash_filters.conf
          type: tosca.artifacts.File
      - outputs_conf:
          file: conf/3-1_logstash_outputs.conf
          type: tosca.artifacts.File
      - extra_host:
          file: artifactsFiles/hosts_to_add.txt
          type: tosca.artifacts.File

  org.ystia.logstash.linux.bash.nodes.GeoNames:
    derived_from: org.ystia.consul.pub.nodes.ConsulUser
    description: A GeoNames connector for Logstash on linux
    tags:
      icon: /images/geonames.gif
    properties:
      repository:
        type: string
        description: >
          The repository to download the geonames archives.
          You may want to specify a local directory where you have previously copied the archive files.
        required: false
        default: http://download.geonames.org/export/dump/
        constraints:
          - pattern: ^(http|https|ftp)://.+/.*$
      filename:
        type: string
        default: allCountries
        description: >
          Name of the file containing GeoNames data
          Choose allCountries to get a complete information (very heavy)
          You can choose a country code in capitals (US, FR, ...)
          Or another file like cities15000 or cities5000
          A .zip suffix will be added to this name.
        required: true
      indexname:
        type: string
        default: geonames
        description: >
          Name of index to store GeoNames data
        required: true
    capabilities:
      geonames_resource: org.ystia.logstash.pub.capabilities.GeonamesEndpoint
    requirements:
      - host:
          capability: org.ystia.logstash.pub.capabilities.LogstashConnectorHosting
          relationship: org.ystia.logstash.linux.bash.relationships.GeonamesHostedOnLogstash
          occurrences: [1,1]
    interfaces:
      Standard:
          create:
            inputs:
              REPOSITORY: { get_property: [SELF, repository] }
              FNAME: { get_property: [SELF, filename] }
            implementation: geonames/create.sh
          start:
            implementation: geonames/start.sh
          stop:
            implementation: geonames/stop.sh
      custom:
          update:
            inputs:
              REPOSITORY: { get_property: [SELF, repository] }
              FNAME:
                type: string
                description: File name used for update (without .zip suffix)
                required: true
            implementation: geonames/update.sh
    artifacts:
      - geoscripts:
          file: geonames
          type: tosca.artifacts.File
      - scripts:
          file: scripts
          type: tosca.artifacts.File

relationship_types:
  org.ystia.logstash.linux.bash.relationships.LogstashToKafka:
    # TODO (HJo) : Janus issue
#    derived_from: org.ystia.kafka.pub.relationships.PublishToKafkaTopic
    derived_from: org.ystia.kafka.linux.bash.relationships.PublishToKafkaTopic
    description: Connects Logstash to Kafka
    valid_target_types: [ org.ystia.kafka.pub.capabilities.KafkaTopic ]
    interfaces:
      Configure:
        pre_configure_source:
          inputs:
            TOPIC_NAME: { get_property: [TARGET, topic_name] }
            REQUIRED_ACKS: { get_property: [SELF, request_required_acks] }
            MESSAGE_MAX_RETRIES: { get_property: [SELF, message_send_max_retries] }
            RETRY_BACKOFF_MS: { get_property: [SELF, retry_backoff_ms] }
            REQUEST_TIMEOUT_MS: { get_property: [SELF, request_timeout_ms] }
          implementation: relationships/kafka/configure-kafka-output.sh
    artifacts:
      - scripts:
          file: scripts
          type: tosca.artifacts.File

  org.ystia.logstash.linux.bash.relationships.KafkaToLogstash:
    # TODO (HJo) : Janus issue
    #    derived_from: org.ystia.kafka.pub.relationships.ConnectsToKafkaTopic
    derived_from: org.ystia.kafka.linux.bash.relationships.ConnectsToKafkaTopic
    description: Connects Kafka to Logstash
    valid_target_types: [ org.ystia.kafka.pub.capabilities.KafkaTopic ]
    interfaces:
      Configure:
          pre_configure_source:
            inputs:
              TOPIC_NAME: { get_property: [TARGET, topic_name] }
            implementation: relationships/kafka/configure-kafka-input.sh
    artifacts:
      - scripts:
          file: scripts
          type: tosca.artifacts.File

  org.ystia.logstash.linux.bash.relationships.LogstashToElasticsearch:
    derived_from: org.ystia.relationships.ConnectsTo
    description: Connects Logstash to ElasticSearch
    valid_target_types: [ org.ystia.elasticsearch.pub.capabilities.SearchEndpoint ]
    interfaces:
      Configure:
          pre_configure_source:
            inputs:
              LOGSTASH_HOME: { get_attribute: [SOURCE, ls_home] }
              cluster_name: { get_property: [ TARGET, cluster_name ] }
            implementation: relationships/elasticsearch/configure.sh
    artifacts:
      - scripts:
          file: scripts
          type: tosca.artifacts.File

  org.ystia.logstash.linux.bash.relationships.GeonamesHostedOnLogstash:
    derived_from: org.ystia.relationships.HostedOn
    description: Connects Geonames to Logstash
    valid_target_types: [ org.ystia.logstash.pub.capabilities.LogstashConnectorHosting ]
    interfaces:
      Configure:
          post_configure_source:
            implementation: relationships/geonames/geonames_to_logstash.sh
            inputs:
              LOGSTASH_HOME: { get_attribute: [TARGET, ls_home] }
              REPOSITORY: { get_property: [SOURCE, repository] }
              INDEX: { get_property: [SOURCE, indexname] }
              FNAME: { get_property: [SOURCE, filename] }
    artifacts:
      - conf:
          file: conf
          type: tosca.artifacts.File
      - geoscripts:
          file: geonames
          type: tosca.artifacts.File
      - lsscripts:
          file: scripts
          type: tosca.artifacts.File
      - rsgeoscripts:
          file: relationships/geonames
          type: tosca.artifacts.File
